{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMnR2zzCwRzb",
        "outputId": "7b86b91e-e4c6-4f27-c3d9-208caebcaf4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras\n",
        "!pip install scikit-learn\n",
        "!pip install tqdm\n",
        "!pip install numpy\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyVLgs_24qKR",
        "outputId": "1911501a-5c21-4149-c759-3ca51d0c4094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH346pPF7LY3",
        "outputId": "29650948-72c6-442e-e017-67a0b383524d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foA5CbET7Orr",
        "outputId": "0802f65c-b3a8-45e0-a685-6f96701518db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-1.1.3-cp310-cp310-manylinux1_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install dgl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNF842Mk9hnl",
        "outputId": "d5e0393a-572f-415e-c07f-28e36b34855c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PybCHgXCAGiJ",
        "outputId": "b2ff9225-0e37-449c-ebb5-0bdc73561bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['raw', 'processed']\n"
          ]
        }
      ],
      "source": [
        "gossipcop_folder_path = '/content/drive/My Drive/GNN/gossipcop'\n",
        "politifact_folder_path = '/content/drive/My Drive/GNN/politifact'\n",
        "\n",
        "# Example: Listing files in the gossipcop folder\n",
        "import os\n",
        "gossipcop_files = os.listdir(gossipcop_folder_path)\n",
        "print(gossipcop_files)  # This will print the names of the files in the gossipcop folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDcPvq-VGlYE",
        "outputId": "bc4eb2b7-5930-4454-b61b-56105ea86bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Building wheels for collected packages: torch-sparse, torch-scatter, torch-cluster\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1035675 sha256=cad5a6460171ae8bb608a65aef231d9947bedc8ef7749e5963677bd381709010\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=495091 sha256=d0ce0ad988665290fdac3de6566869f7420598f2d5a5e9a44d4e7f5e88c49db0\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl size=690648 sha256=d48e39f42b156d1e2574b0cb546ae8bfadbddfb8194663be55cf73387dca9b0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/78/c3/536637b3cdcc3313aa5e8851a6c72b97f6a01877e68c7595e3\n",
            "Successfully built torch-sparse torch-scatter torch-cluster\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3 torch-scatter-2.1.2 torch-sparse-0.6.18\n"
          ]
        }
      ],
      "source": [
        "# Install torch_sparse and related PyTorch Geometric packages\n",
        "!pip install torch-sparse torch-scatter torch-cluster torch-geometric\n",
        "\n",
        "# After installation, you can now import torch_sparse\n",
        "from torch_sparse import coalesce"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ipm586hGUw4"
      },
      "source": [
        "data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh3HR4cRj9-v",
        "outputId": "17fb0134-4f28-43fa-b82b-bb1af3deaaf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File exists: False\n"
          ]
        }
      ],
      "source": [
        "file_path = '/content/drive/My Drive/GNN/gossipcop/new_spacy_feature.npz'\n",
        "print(\"File exists:\", os.path.exists(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUCXqDl57TU0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "from torch_geometric.utils import to_undirected, add_self_loops\n",
        "from torch_sparse import coalesce\n",
        "from torch_geometric.io import read_txt_array\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import random\n",
        "\n",
        "# Function to read a file from disk\n",
        "def read_file(folder, name, dtype=None):\n",
        "    path = os.path.join(folder, f'{name}.txt')\n",
        "    return read_txt_array(path, sep=',', dtype=dtype)\n",
        "\n",
        "# Function to split data into graph batches\n",
        "def split(data, batch):\n",
        "    node_slice = torch.cumsum(torch.from_numpy(np.bincount(batch)), 0)\n",
        "    node_slice = torch.cat([torch.tensor([0]), node_slice])\n",
        "\n",
        "    row, _ = data.edge_index\n",
        "    edge_slice = torch.cumsum(torch.from_numpy(np.bincount(batch[row])), 0)\n",
        "    edge_slice = torch.cat([torch.tensor([0]), edge_slice])\n",
        "\n",
        "    data.edge_index -= node_slice[batch[row]].unsqueeze(0)\n",
        "    data.__num_nodes__ = torch.bincount(batch).tolist()\n",
        "\n",
        "    slices = {'edge_index': edge_slice}\n",
        "    for attr in ['x', 'edge_attr', 'y']:\n",
        "        item = getattr(data, attr, None)\n",
        "        if item is not None:\n",
        "            if item.size(0) == batch.size(0):\n",
        "                slices[attr] = node_slice\n",
        "            else:\n",
        "                slices[attr] = torch.arange(0, batch[-1] + 2, dtype=torch.long)\n",
        "    return data, slices\n",
        "\n",
        "# Function to read and process graph data\n",
        "def read_graph_data(folder, feature):\n",
        "    node_attributes = sp.load_npz(os.path.join(folder, f'new_{feature}_feature.npz'))\n",
        "    edge_index = read_file(folder, 'A', torch.long).t()\n",
        "    node_graph_id = np.load(os.path.join(folder, 'node_graph_id.npy'))\n",
        "    graph_labels = np.load(os.path.join(folder, 'graph_labels.npy'))\n",
        "\n",
        "    x = torch.from_numpy(node_attributes.todense()).to(torch.float)\n",
        "    y = torch.from_numpy(graph_labels).to(torch.long)\n",
        "    _, y = y.unique(sorted=True, return_inverse=True)\n",
        "\n",
        "    num_nodes = edge_index.max().item() + 1 if x is None else x.size(0)\n",
        "    edge_index, _ = add_self_loops(edge_index, None)\n",
        "    edge_index, _ = coalesce(edge_index, None, num_nodes, num_nodes)\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    data, slices = split(data, torch.from_numpy(node_graph_id).to(torch.long))\n",
        "\n",
        "    return data, slices\n",
        "\n",
        "# Custom dataset class\n",
        "class FNNDataset(InMemoryDataset):\n",
        "    def __init__(self, root, feature='spacy', empty=False, transform=None, pre_transform=None, pre_filter=None):\n",
        "        self.root = root\n",
        "        self.feature = feature\n",
        "        super(FNNDataset, self).__init__(self.root, transform, pre_transform, pre_filter)\n",
        "        if not empty:\n",
        "            self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [f'new_{self.feature}_feature.npz', 'A.txt', 'node_graph_id.npy', 'graph_labels.npy']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def download(self):\n",
        "        # Data should be pre-downloaded in Google Drive\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.data, self.slices = read_graph_data(self.raw_dir, self.feature)\n",
        "        torch.save((self.data, self.slices), self.processed_paths[0])\n",
        "\n",
        "# Example of using the dataset\n",
        "dataset = FNNDataset(root='/content/drive/My Drive/GNN/gossipcop', feature='spacy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LB6QjWGqNFf"
      },
      "source": [
        "eval_helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1687sXr9J6l"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, roc_auc_score, average_precision_score\n",
        "\n",
        "def eval_deep(log, loader):\n",
        "    \"\"\"\n",
        "    Evaluate the classification performance given mini-batch data.\n",
        "    \"\"\"\n",
        "    data_size = len(loader.dataset.indices)\n",
        "    batch_size = loader.batch_size\n",
        "    size_list = [batch_size] * (data_size // batch_size) + [data_size % batch_size] if data_size % batch_size else [batch_size] * (data_size // batch_size)\n",
        "\n",
        "    assert len(log) == len(size_list)\n",
        "\n",
        "    # Initialize metrics\n",
        "    metrics = {'accuracy': 0, 'f1_macro': 0, 'f1_micro': 0, 'precision': 0, 'recall': 0}\n",
        "    prob_log, label_log = [], []\n",
        "\n",
        "    # Calculate metrics for each batch\n",
        "    for (pred_prob, true_labels), size in zip(log, size_list):\n",
        "        pred_labels = pred_prob.data.cpu().numpy().argmax(axis=1)\n",
        "        true_labels = true_labels.data.cpu().numpy()\n",
        "\n",
        "        prob_log.extend(pred_prob.data.cpu().numpy()[:, 1])\n",
        "        label_log.extend(true_labels)\n",
        "\n",
        "        metrics['accuracy'] += accuracy_score(true_labels, pred_labels) * size\n",
        "        metrics['f1_macro'] += f1_score(true_labels, pred_labels, average='macro', zero_division=0) * size\n",
        "        metrics['f1_micro'] += f1_score(true_labels, pred_labels, average='micro', zero_division=0) * size\n",
        "        metrics['precision'] += precision_score(true_labels, pred_labels, zero_division=0) * size\n",
        "        metrics['recall'] += recall_score(true_labels, pred_labels, zero_division=0) * size\n",
        "\n",
        "    # Normalize by total data size\n",
        "    for key in metrics:\n",
        "        metrics[key] /= data_size\n",
        "\n",
        "    metrics['auc'] = roc_auc_score(label_log, prob_log)\n",
        "    metrics['ap'] = average_precision_score(label_log, prob_log)\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTyBjDBk41R4"
      },
      "source": [
        "big_cn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TGIN5o920WX",
        "outputId": "634bd83c-bf71-4d74-d54c-86e3289139e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [00:00<00:00, 78.40it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch_scatter import scatter_mean\n",
        "from torch_geometric.data import Data, Batch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# GNN Layer Definition\n",
        "class GNNLayer(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GNNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_feats, out_feats)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        return F.relu(x), x\n",
        "\n",
        "# Bi-Directional GCN Model\n",
        "class BiGCN(torch.nn.Module):\n",
        "    def __init__(self, in_feats, hid_feats, out_feats):\n",
        "        super(BiGCN, self).__init__()\n",
        "        self.TD_layer = GNNLayer(in_feats, hid_feats)\n",
        "        self.BU_layer = GNNLayer(in_feats, hid_feats)\n",
        "        self.fc = torch.nn.Linear(hid_feats * 4, out_feats)\n",
        "\n",
        "    def forward(self, data):\n",
        "        td_x, td_x_copy = self.TD_layer(data.x, data.edge_index)\n",
        "        bu_x, bu_x_copy = self.BU_layer(data.x, data.edge_index)\n",
        "\n",
        "        td_x = torch.cat((td_x, td_x_copy), 1)\n",
        "        bu_x = torch.cat((bu_x, bu_x_copy), 1)\n",
        "        x = torch.cat((td_x, bu_x), 1)\n",
        "        x = scatter_mean(x, data.batch, dim=0)\n",
        "        return F.log_softmax(self.fc(x), dim=1)\n",
        "\n",
        "# Sample Dataset\n",
        "class SampleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, size=100):\n",
        "        self.size = size\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.randn(16, 3)  # Node features\n",
        "        edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
        "        return Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# Parameters\n",
        "class Args:\n",
        "    batch_size = 128\n",
        "    epochs = 45\n",
        "    nhid = 128\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# Dataset and DataLoader Setup\n",
        "dataset = SampleDataset()\n",
        "num_training = int(len(dataset) * 0.8)\n",
        "num_test = len(dataset) - num_training\n",
        "training_set, test_set = random_split(dataset, [num_training, num_test])\n",
        "\n",
        "train_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "# Model Setup\n",
        "model = BiGCN(in_feats=3, hid_feats=args.nhid, out_feats=2)\n",
        "model = model.to(args.device)\n",
        "\n",
        "# Training Loop\n",
        "model.train()\n",
        "for epoch in tqdm(range(args.epochs)):\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(args.device)\n",
        "        out = model(batch)\n",
        "        # Add your loss and optimizer steps here\n",
        "\n",
        "# Note: Add your loss function, optimizer, and evaluation steps according to your task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8499575RDZMU"
      },
      "source": [
        "gcnfn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTrHQ-9S5LOI",
        "outputId": "0ed8c57a-6589-4d79-c639-7b62952a9077"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60/60 [00:03<00:00, 16.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.4500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GATConv, global_mean_pool, Linear\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Sample Dataset\n",
        "class SampleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, size=100, num_features=310, num_classes=2):\n",
        "        self.size = size\n",
        "        self.num_features = num_features\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch_geometric.data.Data()\n",
        "        data.x = torch.randn(16, self.num_features)  # Node features\n",
        "        data.edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)  # Edge indices\n",
        "        data.y = torch.randint(0, self.num_classes, (1,))  # Label\n",
        "        return data\n",
        "\n",
        "# GCNFN Model\n",
        "class GCNFN(torch.nn.Module):\n",
        "    def __init__(self, num_features, nhid, num_classes, concat=False):\n",
        "        super(GCNFN, self).__init__()\n",
        "        self.concat = concat\n",
        "        self.conv1 = GATConv(num_features, nhid * 2)\n",
        "        self.conv2 = GATConv(nhid * 2, nhid * 2)\n",
        "\n",
        "        if concat:\n",
        "            self.fc0 = Linear(num_features, nhid)\n",
        "            self.fc1 = Linear(nhid * 2 + nhid, nhid)  # Adjusted input size after concatenation\n",
        "        else:\n",
        "            self.fc1 = Linear(nhid * 2, nhid)  # Only nhid * 2 from conv2\n",
        "\n",
        "        self.fc2 = Linear(nhid, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = F.selu(self.conv1(x, edge_index))\n",
        "        x = F.selu(self.conv2(x, edge_index))\n",
        "        x = F.selu(global_mean_pool(x, batch))\n",
        "\n",
        "        if self.concat:\n",
        "            news = torch.stack([torch.mean(data.x[data.batch == idx], dim=0) for idx in torch.unique(data.batch)])\n",
        "            news = F.relu(self.fc0(news))\n",
        "            x = torch.cat([x, news], dim=1)\n",
        "\n",
        "        x = F.selu(self.fc1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = F.log_softmax(self.fc2(x), dim=-1)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Settings\n",
        "num_features = 310\n",
        "nhid = 128\n",
        "num_classes = 2\n",
        "batch_size = 128\n",
        "epochs = 60\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset = SampleDataset(num_features=num_features, num_classes=num_classes)\n",
        "train_set, test_set = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Model\n",
        "model = GCNFN(num_features, nhid, num_classes, concat=True).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "# Training Loop\n",
        "model.train()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "for data in test_loader:\n",
        "    data = data.to(device)\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct += int((pred == data.y).sum())\n",
        "accuracy = correct / len(test_set)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6oWT1krDnQC"
      },
      "source": [
        "gnncl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj5SKNFzDrJT",
        "outputId": "eb808c3b-f7bd-46f7-8eaf-6c63a86d5aa5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 110.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.5500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.data import DataLoader, Data\n",
        "import torch_geometric\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Corrected Sample Dataset Class\n",
        "class SampleDataset(torch_geometric.data.InMemoryDataset):\n",
        "    def __init__(self, root, size=100, features=3, classes=2, transform=None, pre_transform=None):\n",
        "        super(SampleDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.size = size\n",
        "        self.features = features  # Renamed attribute\n",
        "        self.classes = classes    # Renamed attribute\n",
        "        self.data_list = self.generate_data()\n",
        "\n",
        "    def generate_data(self):\n",
        "        data_list = []\n",
        "        for _ in range(self.size):\n",
        "            data = Data()\n",
        "            data.x = torch.randn(10, self.features)  # Node features\n",
        "            data.edge_index = torch.randint(0, 10, (2, 20))  # Edges\n",
        "            data.y = torch.randint(0, self.classes, (1,))  # Graph label\n",
        "            data_list.append(data)\n",
        "        return data_list\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def get(self, idx):\n",
        "        return self.data_list[idx]\n",
        "\n",
        "# Define the GNN Model\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = global_mean_pool(x, data.batch)  # Global pooling\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Settings\n",
        "features = 3   # Number of node features\n",
        "classes = 2    # Number of classes\n",
        "hidden_channels = 16\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset = SampleDataset(root='/tmp/SampleDataset', features=features, classes=classes)\n",
        "train_set, test_set = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "\n",
        "# Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GNN(features, hidden_channels, classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training Loop\n",
        "model.train()\n",
        "for epoch in tqdm(range(10)):  # Set the number of epochs\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "for data in test_loader:\n",
        "    data = data.to(device)\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct += int((pred == data.y).sum())\n",
        "accuracy = correct / len(test_set)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMadR1rUDsWW"
      },
      "source": [
        "gnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgMVMUTeDtZb",
        "outputId": "72e56b3e-7826-4e4f-9b03-709399c850ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 47.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, global_max_pool as gmp\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Sample Dataset Class (replace with your actual dataset)\n",
        "class SampleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, size=100, num_features=3, num_classes=2):\n",
        "        self.size = size\n",
        "        self.num_features = num_features\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = Data()\n",
        "        data.x = torch.randn(10, self.num_features)  # Node features\n",
        "        data.edge_index = torch.randint(0, 10, (2, 20))  # Edges\n",
        "        data.y = torch.randint(0, self.num_classes, (1,))  # Graph label\n",
        "        return data\n",
        "\n",
        "# Define the Model\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, num_features, nhid, num_classes, model_type='gcn', concat=False):\n",
        "        super(Model, self).__init__()\n",
        "        self.num_features = num_features  # Define num_features as an instance attribute\n",
        "        self.concat = concat\n",
        "\n",
        "        if model_type == 'gcn':\n",
        "            self.conv1 = GCNConv(num_features, nhid)\n",
        "        elif model_type == 'sage':\n",
        "            self.conv1 = SAGEConv(num_features, nhid)\n",
        "        elif model_type == 'gat':\n",
        "            self.conv1 = GATConv(num_features, nhid)\n",
        "\n",
        "        if concat:\n",
        "            self.lin0 = torch.nn.Linear(num_features, nhid)\n",
        "            self.lin1 = torch.nn.Linear(nhid + nhid, nhid)\n",
        "        else:\n",
        "            self.lin1 = torch.nn.Linear(nhid, nhid)\n",
        "\n",
        "        self.lin2 = torch.nn.Linear(nhid, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = gmp(x, data.batch)  # Global max pooling\n",
        "\n",
        "        if self.concat:\n",
        "            news = torch.cat([data.x[data.batch == idx][0] for idx in torch.unique(data.batch)], dim=0)\n",
        "            news = news.view(-1, self.num_features)  # Reshape to match features\n",
        "            news = F.relu(self.lin0(news))\n",
        "            x = torch.cat([x, news], dim=1)\n",
        "            x = F.relu(self.lin1(x))\n",
        "\n",
        "        x = F.log_softmax(self.lin2(x), dim=-1)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Settings\n",
        "num_features = 3\n",
        "nhid = 128\n",
        "num_classes = 2\n",
        "batch_size = 128\n",
        "epochs = 35\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset = SampleDataset(num_features=num_features, num_classes=num_classes)\n",
        "train_set, test_set = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Model\n",
        "model = Model(num_features, nhid, num_classes, model_type='sage', concat=True).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training and Evaluation\n",
        "model.train()\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "for data in test_loader:\n",
        "    data = data.to(device)\n",
        "    out = model(data)\n",
        "    pred = out.argmax(dim=1)\n",
        "    correct += int((pred == data.y).sum())\n",
        "accuracy = correct / len(test_set)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaKUBwi1UtJR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}